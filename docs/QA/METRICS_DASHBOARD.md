# QA Metrics Dashboard

**Generated**: 2025-08-22T15:26:49.167Z  
**Data Points**: 2 test runs  
**Latest Run**: 2025-08-22T15:26:48.863Z

## 🔍 Latest Results

### Summary
- **PR/Branch**: N/A (local)
- **Success Rate**: 100% (2/2)
- **Tools Available**: 42
- **Failed Tests**: 0
- **Skipped Tests**: 0

### Performance
- **Average Response Time**: 149ms
- **95th Percentile**: 202ms
- **Total Test Duration**: 297ms
- **Server Startup Time**: 0ms
- **Peak Memory Usage**: 78MB

### Environment
- **CI**: Local
- **Node Version**: v24.1.0
- **Platform**: darwin

## 📈 Trends

| Metric | Trend | Description |
|--------|-------|-------------|
| Success Rate | 📈 increasing (25%, 33pp) | Test pass rate over time |
| Response Time | 📈 increasing (16ms, 12%) | Average API response speed |
| Memory Usage | 📈 increasing (33MB, 75%) | Peak memory consumption |
| Test Count | 📉 decreasing (-3, -60%) | Number of tests executed |

## 📊 Historical Data (Last 2 Runs)

| Date | Time | PR/Branch | Success Rate | Tools | Avg Time | P95 Time | Tests | Failed | Memory |
|------|------|-----------|-------------|-------|----------|----------|-------|---------|---------|
| 2025-08-22 | 15:26:48 | N/A/local | 100% | 42 | 149ms | 202ms | 2 | 0 | 78MB |
| 2025-08-22 | 15:21:59 | local/local | 75% | 42 | 133ms | 300ms | 5 | 1 | 44MB |

## 📊 Performance Charts

### Success Rate Trend
```
PRN/A    │██████████████████████████████████████████████████│ 100%
local    │██████████████████████████████████████░░░░░░░░░░░░│ 75%
         └──────────────────────────────────────────────────┘
          0%                                            100%
```

### Response Time Trend
```
PRN/A    │██████████████████████████████████████████████████│ 149ms
local    │█████████████████████████████████████████████░░░░░│ 133ms
         └──────────────────────────────────────────────────┘
          0ms                                         149ms
```

## 🔧 Usage

This dashboard is automatically generated by `scripts/qa-dashboard-generator.js`.

### Commands
```bash
# Generate dashboard manually
node scripts/qa-dashboard-generator.js

# Run QA tests (will update metrics)
npm run qa:test

# View all metrics files
ls -la docs/QA/metrics/
```

### Metrics Collection
Metrics are automatically collected during QA test runs and saved to `docs/QA/metrics/`. Each test run generates a timestamped JSON file with comprehensive performance and reliability data.

---
*Dashboard generated by DollhouseMCP QA Metrics System*
